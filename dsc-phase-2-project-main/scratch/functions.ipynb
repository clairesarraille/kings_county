{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split normalized data into target variable and predictors/explanatory variables/independent variables\n",
    "X = df_norm.drop(['price','price_millions'], axis=1) # independent variables\n",
    "y = df_norm['price_millions'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=4)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "predict_y_train = lr.predict(X_train)\n",
    "print('The R squared value is: ' + str(metrics.r2_score(y_train, predict_y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train, predict_y_train)\n",
    "plt.xlabel('price - millions')\n",
    "plt.ylabel('predicted price - millions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(predict_y_train, y_train - predict_y_train)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_pred = df_water.drop(['price','price_millions'], axis=1)\n",
    "house_target = df_water['price_millions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = sm.add_constant(house_pred)\n",
    "model = sm.OLS(house_target, predictors).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanded SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split normalized data into target variable and predictors/explanatory variables/independent variables\n",
    "X = df_norm.drop(['price','price_millions'], axis=1) # independent variables\n",
    "y = df_norm['price_millions'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into test and train data\n",
    "# Train data is for us to estimate our OLS model\n",
    "# Test data is to parameterize our model, using that model to predict y values (price)\n",
    "# If test_size = .3, that means 30% of our data is set aside for teh testing data\n",
    "# And 70% of that data for training\n",
    "\n",
    "# The parameter \"random_state\" ensures that if there is skew in our data, our 30-70 split is randomly taking from these groups\n",
    "# So we have good proportions of randomly selected data and our 30-70 split has good representation \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regressor - Ordinary Least Squares regression-type estimate:\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model based on train dataset:\n",
    "# Regressing the X's onto the y:\n",
    "# We're getting a fit here, having used 70% of the data\n",
    "lr.fit(X_train, y_train)\n",
    "coef_list = list(lr.coef_)\n",
    "name_list = list(X_train.columns)\n",
    "pd.Series(coef_list, index=name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction based on train dataset:\n",
    "predict_y_train = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Prices vs. Predicted Prices:\n",
    "plt.scatter(y_train, predict_y_train)\n",
    "plt.xlabel('price')\n",
    "plt.ylabel('predicted price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret price vs. predicted price scatterplot:\n",
    "- The distribution isn't a straight line, and from that we know that there is something non-linear going on in the relationships we've modeled. \n",
    "- We don't have a good linear relationship between price and our predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we take the 30% of that data we set aside for testing, and examine the error for that:\n",
    "predict_y_test = lr.predict(X_test)\n",
    "print('The R squared value is: ' + str(metrics.r2_score(y_test, predict_y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So looks like in-sample, out-of-sample is not as robust as we might want, \n",
    "# since our R-squared value is less than when using train data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
